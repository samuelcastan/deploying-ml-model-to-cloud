name: train_pipeline
python_env: python_env.yaml

entry_points:
  main:
    parameters:
      
      clean_data:
        description: Path where clean data was saved locally
        type: string

      cat_features:
        description: categorical features to use for training and inferencing
        type: string

      target:
        description: target variable  
        type: string

      test_size:
        description: Size (percentage in decimal) to split the training dataset
        type: string
      
      random_state:
        description: Reproducibility number
        type: string
      
      n_estimators:
        description: Random forest hyperaparameter
        type: string
      
      max_depth:
        description: Random forest hyperaparameter
        type: string
      
      max_features:
        description: Random forest hyperaparameter
        type: string
      
      random_state_rf:
        description: Random state for reproducibility for Random forest model
        type: string

      n_jobs:
        description: Enables using all the CPU cores for traing random forest
        type: string
      
      pipeline_path:
        description: Path to save trained pipeline
        type: string

      classification_report:
        description: Path to save classification report
        type: string

      data_slice_report:
        description: Path to save data slice report
        type: string


    command: >-
        python run.py --clean_data {clean_data} --cat_features {cat_features} --target {target} --test_size {test_size} --random_state {random_state} --n_estimators {n_estimators} --max_depth {max_depth} --max_features {max_features} --random_state_rf {random_state_rf} --n_jobs {n_jobs} --pipeline_path {pipeline_path} --classification_report {classification_report} --data_slice_report {data_slice_report}
